\section{Introduction}
The autonomous navigation is understood as the set of techniques by which it is a system able to move with a certain level of autonomy in a certain type of environment (land, air, underwater, space). The problems in the field of autonomous navigation are addressed first and foremost related to the localization of the system with respect to the environment, planning out their duties and motion control.
An interesting class of systems covered by the study of autonomous navigation systems is that of the AGV (Autonomous Guided Vehicles). They are now widely used in industries, ports, airports, hospitals, etc, however, to measure the position and the attitude of a vehicle it is still a problem of substantial interest.
The sensor fusion is the process that combines information from a number of different sources to provide a complete and robust description (measure) a set of variables of interest. The sensor fusion is of particular utility in any application where many measures have to be combined together, melted and optimized in order to obtain quality information and integrity suitable for the purpose of the application. The sensor fusion techniques are used in many industrial systems, military, monitoring, civilian surveillance, control processes and systems. The problem of localization of autonomous vehicles, which in almost all cases, the individual transducers are found insufficient in setting up a comprehensive and robust localization system for autonomous navigation, requires the use of sensor fusion techniques for combining measurements from different types of transducers whose characteristics, if fused together, allow us to obtain a more reliable and accurate measure of the state of the system and the environment surrounding it.
The sensor fusion techniques have important applications in the field of autonomous navigation, in which it is necessary to obtain a good estimate of the position measurement and alignment (pose) of a mobile robot. Incremental measuring methods or dead-reckoning, using encoders, gyroscopes, ultrasonic, etc., have the considerable advantages of being self-contained within the robot, to be relatively simple to use and provide high refresh rate measure. On the other hand, since these measurement systems integrate related increments, the errors grow considerably increasing the integration time.
The document presented is based on the analysis of a real robot, developed and built at the MIRO - Measurements Instrumentations Robotics Lab at the University of Trento.
It is equipped with two rotary incremental encoder keyed to the axes of the two wheels and a chamber pointing upwards for reading specially arranged on the ceiling marker.
The two datasets have been collected steering the vehicle clockwise and counterclockwise.
The aim of the homework is to:
\begin{itemize}
\item Estimate from the encoder and the camera data the kinematics parameters wheels radius "$r_\textsc{l}$" and "$r_\textsc{r}$" and wheelbase "$b$".
\item Estimate the camera position with respect to the wheelchair reference point (the mid point between the wheels).
\end{itemize}